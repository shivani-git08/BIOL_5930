{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDEUvHFJipzD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PARALLEL COMPUTING SCRIPT(NO OUTLIER)**"
      ],
      "metadata": {
        "id": "J9RC7HUq1JQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from scipy.optimize import curve_fit\n",
        "import math\n",
        "\n",
        "def logistic_function(x, L, k, x0):\n",
        "    return L / (1 + np.exp(-k * (x - x0)))\n",
        "\n",
        "\n",
        "def get_cell_line_order(input_file):\n",
        "    df = pd.read_excel(input_file, header=7)\n",
        "    return [col.split(' ')[0] for col in df.columns if col != 'Elapsed' and col != 'Date Time']\n",
        "\n",
        "\n",
        "def calculate_mean_std_dev_and_counts(input_file, output_file):\n",
        "    df = pd.read_excel(input_file, header=7)\n",
        "    df['Elapsed'] = pd.to_numeric(df['Elapsed'], errors='coerce')\n",
        "    df = df[df['Elapsed'].between(0, 140)]\n",
        "    elapsed_time = df['Elapsed']\n",
        "\n",
        "\n",
        "    cell_line_order = get_cell_line_order(input_file)\n",
        "    combined_data = {'Elapsed': elapsed_time}\n",
        "\n",
        "\n",
        "    for prefix in cell_line_order:\n",
        "        columns = [col for col in df.columns if col.startswith(prefix + ' ') and col != 'Date Time']\n",
        "        if columns:\n",
        "            cell_line_data = df[columns]\n",
        "            combined_data[f\"{prefix} Mean\"] = cell_line_data.mean(axis=1)\n",
        "            combined_data[f\"{prefix} STD DEV\"] = cell_line_data.std(axis=1)\n",
        "            combined_data[f\"{prefix} COUNTS\"] = [f\"{prefix} - {cell_line_data.shape[1]}\"] * len(elapsed_time)\n",
        "\n",
        "    combined_df = pd.DataFrame(combined_data)\n",
        "    combined_df.to_excel(output_file, index=False)\n",
        "\n",
        "\n",
        "def calculate_growth_rates_and_doubling_times(data_file, output_file):\n",
        "    data = pd.read_excel(data_file)\n",
        "    elapsed_time = data['Elapsed'].values\n",
        "    columns_to_calculate = [col for col in data.columns if col.endswith(' Mean')]\n",
        "    growth_rates_and_doubling_times = []\n",
        "\n",
        "    for column in columns_to_calculate:\n",
        "        par_mean = data[column].values\n",
        "        valid_elapsed = elapsed_time[~np.isnan(par_mean)]\n",
        "        valid_par_mean = par_mean[~np.isnan(par_mean)]\n",
        "\n",
        "        if len(valid_par_mean) > 0:\n",
        "            try:\n",
        "                y_max, y_min = np.nanmax(valid_par_mean), np.nanmin(valid_par_mean)\n",
        "                x_max, x_min = np.nanmax(valid_elapsed), np.nanmin(valid_elapsed)\n",
        "                x_mid, y_mid = (x_max + x_min) / 2, (y_max + y_min) / 2\n",
        "                L_init, k_init = y_max, 4 / (x_max - x_min)\n",
        "                x0_init = x_mid - np.log((y_max - y_mid) / (y_mid - y_min)) / k_init\n",
        "\n",
        "                popt, _ = curve_fit(logistic_function, valid_elapsed, valid_par_mean, p0=[L_init, k_init, x0_init])\n",
        "                L_opt, k_opt, x0_opt = popt\n",
        "                growth_rate = k_opt\n",
        "                doubling_time = math.log(2) / growth_rate\n",
        "            except:\n",
        "                L_opt, k_opt, x0_opt = np.nan, np.nan, np.nan\n",
        "                growth_rate = np.nan\n",
        "                doubling_time = np.nan\n",
        "        else:\n",
        "            L_opt, k_opt, x0_opt = np.nan, np.nan, np.nan\n",
        "            growth_rate = np.nan\n",
        "            doubling_time = np.nan\n",
        "\n",
        "        growth_rates_and_doubling_times.append({\n",
        "            'Column': column.replace(' Mean', ''),\n",
        "            'Growth Rate': growth_rate,\n",
        "            'Doubling Time': doubling_time,\n",
        "            'Max Carrying Capacity (L)': L_opt,\n",
        "            'Midpoint (x0)': x0_opt,\n",
        "            'Time Range': f\"0 to {np.max(valid_elapsed):.2f} hours\" if len(valid_elapsed) > 0 else \"N/A\"\n",
        "        })\n",
        "\n",
        "    growth_rate_and_doubling_time_df = pd.DataFrame(growth_rates_and_doubling_times)\n",
        "    growth_rate_and_doubling_time_df.to_excel(output_file, index=False)\n",
        "\n",
        "def plot_smooth_growth_curve(input_file, output_image):\n",
        "    df = pd.read_excel(input_file)\n",
        "    elapsed_time = df['Elapsed']\n",
        "\n",
        "    columns_to_plot = [col for col in df.columns if col.endswith(' Mean')]\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    colors = plt.cm.get_cmap('tab10', len(columns_to_plot))\n",
        "\n",
        "    for i, column in enumerate(columns_to_plot):\n",
        "        mean_data = df[column]\n",
        "        std_column = column.replace(' Mean', ' STD DEV')\n",
        "        std_data = df[std_column]\n",
        "\n",
        "        if not mean_data.isnull().all():\n",
        "            spline_mean = make_interp_spline(elapsed_time, mean_data, k=3)\n",
        "            smooth_time = np.linspace(elapsed_time.min(), elapsed_time.max(), 500)\n",
        "            smooth_mean = spline_mean(smooth_time)\n",
        "\n",
        "            plt.plot(smooth_time, smooth_mean, label=column.replace(' Mean', ''), color=colors(i))\n",
        "            plt.errorbar(elapsed_time, mean_data, yerr=std_data, fmt='o', capsize=2, color=colors(i))\n",
        "\n",
        "    plt.xlabel('Time (hours)')\n",
        "    plt.ylabel('% Confluence')\n",
        "    plt.title('Growth Curve')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(np.arange(0, 141, 24))\n",
        "    plt.savefig(output_image, format='png')\n",
        "    plt.close()\n",
        "\n",
        "def process_files(file_list, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for input_file in file_list:\n",
        "        filename = os.path.splitext(os.path.basename(input_file))[0]\n",
        "\n",
        "        mean_std_dev_counts_output = os.path.join(output_dir, f\"{filename}_mean_stdev_counts.xlsx\")\n",
        "        growth_rate_and_doubling_time_output = os.path.join(output_dir, f\"{filename}_GR_DT.xlsx\")\n",
        "        growth_curve_output_image = os.path.join(output_dir, f\"{filename}_growth_curve.png\")\n",
        "\n",
        "        calculate_mean_std_dev_and_counts(input_file, mean_std_dev_counts_output)\n",
        "        calculate_growth_rates_and_doubling_times(mean_std_dev_counts_output, growth_rate_and_doubling_time_output)\n",
        "        plot_smooth_growth_curve(mean_std_dev_counts_output, growth_curve_output_image)\n",
        "\n",
        "def main():\n",
        "    # List of input files\n",
        "    input_files = [\n",
        "    ]\n",
        "\n",
        "    output_dir = \"output\"\n",
        "\n",
        "    process_files(input_files, output_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "GQOch_VDIRaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_oupjF-ki-yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qm_yvsLAjDpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6numTP4jDmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEPS FOR OUTLIER REMOVAL**"
      ],
      "metadata": {
        "id": "7Kw1TUifjjFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FILTERING DATA FOR 24HR**"
      ],
      "metadata": {
        "id": "YkmNQKNjjIXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Function to process data for a given elapsed time\n",
        "def process_data(elapsed_time, file_name, output_file):\n",
        "    # Read data from the Excel file\n",
        "    df = pd.read_excel(file_name, header=7)\n",
        "\n",
        "    # Filter the dataframe for rows where 'Elapsed' matches the specified time\n",
        "    cutrow = df[df['Elapsed'] == elapsed_time].drop(columns=[\"Elapsed\", \"Date Time\"]).T\n",
        "\n",
        "    # Assign 'my_list' values\n",
        "    cutrow['my_list'] = [i for i in range(1, 9) for _ in range(12)]\n",
        "\n",
        "    # Create a new DataFrame 'wide' with a column 'Rep' containing numbers from 1 to 12\n",
        "    wide = pd.DataFrame({\"Rep\": range(1, 13)})\n",
        "\n",
        "    # Get the correct column name (assuming it's the only numerical column)\n",
        "    data_columns = [col for col in cutrow.columns if isinstance(col, (int, float))]\n",
        "    if len(data_columns) != 1:\n",
        "        raise ValueError(\"Unexpected number of numerical data columns found.\")\n",
        "\n",
        "    data_column = data_columns[0]\n",
        "\n",
        "    # Iterate over the range from 1 to 8 to filter the 'cutrow' DataFrame and populate 'wide'\n",
        "    for i in range(1, 9):\n",
        "        subset = cutrow[cutrow['my_list'] == i]\n",
        "\n",
        "        if not subset.empty:\n",
        "            column = subset.index[0].split(\" \")[0]\n",
        "\n",
        "            if data_column in subset.columns:  # Ensure the correct data column exists in the subset\n",
        "                wide[column] = subset[data_column].values\n",
        "\n",
        "    # Save the resulting DataFrame to an Excel file\n",
        "    wide.to_excel(output_file, index=False)\n",
        "\n",
        "def process_multiple_files(input_files, output_dir, elapsed_time=24):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for file_name in input_files:\n",
        "        try:\n",
        "            # Generate output file name\n",
        "            base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
        "            output_file = os.path.join(output_dir, f\"{base_name}_{elapsed_time}hr.xlsx\")\n",
        "\n",
        "            # Process the file\n",
        "            process_data(elapsed_time, file_name, output_file)\n",
        "            print(f\"Processed {file_name} and saved results to {output_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_name}: {str(e)}\")\n",
        "\n",
        "# List of input files\n",
        "input_files = [\n",
        "    \"\"\n",
        "        ]\n",
        "\n",
        "# Output directory\n",
        "output_dir = \"processed_data_24hr\"\n",
        "\n",
        "# Process all files\n",
        "process_multiple_files(input_files, output_dir)\n"
      ],
      "metadata": {
        "id": "egjb5dVcuk8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmgQIQUnjMum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsYltepzjMsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCESSED STATS**"
      ],
      "metadata": {
        "id": "HQqFJ0KkjNMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from scipy.stats import iqr\n",
        "\n",
        "def process_file(input_file, output_dir):\n",
        "    # Read the original data from the Excel file\n",
        "    df = pd.read_excel(input_file)\n",
        "\n",
        "    # Get the cell lines present in this file, preserving the original order\n",
        "    file_cell_lines = [col for col in df.columns if col != 'Rep']\n",
        "\n",
        "    # Create a list to store the statistics for each cell line\n",
        "    cell_line_stats = []\n",
        "\n",
        "    # Iterate over cell lines in the order they appear in the file\n",
        "    for cell_line in file_cell_lines:\n",
        "        # Extract the doubling time for the current cell line\n",
        "        doubling_time = df[cell_line]\n",
        "\n",
        "        # Calculate the IQR, Q1, and Q3 for the doubling time\n",
        "        Q1 = doubling_time.quantile(0.25)\n",
        "        Q3 = doubling_time.quantile(0.75)\n",
        "        IQR_value = iqr(doubling_time)\n",
        "\n",
        "        # Calculate the lower and upper limits\n",
        "        lower_limit = Q1 - 1.5 * IQR_value\n",
        "        upper_limit = Q3 + 1.5 * IQR_value\n",
        "\n",
        "        # Calculate mean and standard deviation before removing outliers\n",
        "        mean_before = doubling_time.mean()\n",
        "        std_dev_before = doubling_time.std()\n",
        "\n",
        "        # Identify outliers\n",
        "        outliers = doubling_time[(doubling_time < lower_limit) | (doubling_time > upper_limit)]\n",
        "\n",
        "        # Remove outliers\n",
        "        filtered_doubling_time = doubling_time[(doubling_time >= lower_limit) & (doubling_time <= upper_limit)]\n",
        "\n",
        "        # Calculate mean and standard deviation after removing outliers\n",
        "        mean_after = filtered_doubling_time.mean()\n",
        "        std_dev_after = filtered_doubling_time.std()\n",
        "\n",
        "        # Store the statistics for the current cell line\n",
        "        cell_line_stats.append({\n",
        "            'Cell Line': cell_line,\n",
        "            'IQR': IQR_value,\n",
        "            'Q1': Q1,\n",
        "            'Q3': Q3,\n",
        "            'Lower Limit': lower_limit,\n",
        "            'Upper Limit': upper_limit,\n",
        "            'Mean Before': mean_before,\n",
        "            'Std Dev Before': std_dev_before,\n",
        "            'Mean After': mean_after,\n",
        "            'Std Dev After': std_dev_after,\n",
        "            'Outliers': list(outliers)\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame from the collected statistics\n",
        "    cell_line_stats_df = pd.DataFrame(cell_line_stats)\n",
        "\n",
        "    # Generate output file name\n",
        "    base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
        "    output_file = os.path.join(output_dir, f\"{base_name}_Stats.xlsx\")\n",
        "\n",
        "    # Save the statistics to a new Excel file\n",
        "    cell_line_stats_df.to_excel(output_file, index=False)\n",
        "\n",
        "    print(f\"Processed {input_file} and saved statistics to {output_file}\")\n",
        "\n",
        "def process_multiple_files(input_files, output_dir):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for input_file in input_files:\n",
        "        try:\n",
        "            process_file(input_file, output_dir)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {input_file}: {str(e)}\")\n",
        "\n",
        "# List of input files\n",
        "input_files = [\n",
        "    \"\"\n",
        "    ]\n",
        "\n",
        "# Output directory\n",
        "output_dir = \"processed_stats\"\n",
        "\n",
        "# Process all files\n",
        "process_multiple_files(input_files, output_dir)"
      ],
      "metadata": {
        "id": "1pfVlWeDv_VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-VpyfZh4i-rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kmCf6sFii-oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PARALLEL COMPUTING SCRIPT(OUTLIER_24)**"
      ],
      "metadata": {
        "id": "8F9hHqbEjTxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from scipy.optimize import curve_fit\n",
        "import math\n",
        "\n",
        "def logistic_function(x, L, k, x0):\n",
        "    return L / (1 + np.exp(-k * (x - x0)))\n",
        "\n",
        "def get_cell_line_order(input_file):\n",
        "    df = pd.read_excel(input_file, header=7, sheet_name=\"Outlier_24\")\n",
        "    return [col.split(' ')[0] for col in df.columns if col != 'Elapsed' and col != 'Date Time']\n",
        "\n",
        "def calculate_mean_std_dev_and_counts(input_file, output_file):\n",
        "    df = pd.read_excel(input_file, header=7, sheet_name=\"Outlier_24\")\n",
        "    df['Elapsed'] = pd.to_numeric(df['Elapsed'], errors='coerce')\n",
        "    df = df[df['Elapsed'].between(0, 140)]\n",
        "    elapsed_time = df['Elapsed']\n",
        "\n",
        "    cell_line_order = get_cell_line_order(input_file)\n",
        "    combined_data = {'Elapsed': elapsed_time}\n",
        "\n",
        "    for prefix in cell_line_order:\n",
        "        columns = [col for col in df.columns if col.startswith(prefix + ' ') and col != 'Date Time']\n",
        "        cell_line_data = df[columns].dropna(axis=1, how='all')\n",
        "        if not cell_line_data.empty:\n",
        "            combined_data[f\"{prefix} Mean\"] = cell_line_data.mean(axis=1)\n",
        "            combined_data[f\"{prefix} STD DEV\"] = cell_line_data.std(axis=1)\n",
        "            combined_data[f\"{prefix} COUNTS\"] = [f\"{prefix} - {cell_line_data.shape[1]}\"] * len(elapsed_time)\n",
        "\n",
        "    combined_df = pd.DataFrame(combined_data)\n",
        "    combined_df.to_excel(output_file, index=False)\n",
        "\n",
        "def calculate_growth_rates_and_doubling_times(data_file, output_file):\n",
        "    data = pd.read_excel(data_file)\n",
        "    elapsed_time = data['Elapsed'].values\n",
        "    columns_to_calculate = [col for col in data.columns if col.endswith(' Mean')]\n",
        "    results = []\n",
        "\n",
        "    for column in columns_to_calculate:\n",
        "        par_mean = data[column].values\n",
        "        valid_indices = ~np.isnan(par_mean) & ~np.isnan(elapsed_time)\n",
        "        valid_par_mean = par_mean[valid_indices]\n",
        "        valid_elapsed = elapsed_time[valid_indices]\n",
        "\n",
        "        if len(valid_par_mean) > 0:\n",
        "            try:\n",
        "                y_max, y_min = np.max(valid_par_mean), np.min(valid_par_mean)\n",
        "                x_max, x_min = np.max(valid_elapsed), np.min(valid_elapsed)\n",
        "                x_mid, y_mid = (x_max + x_min) / 2, (y_max + y_min) / 2\n",
        "                L_init, k_init = y_max, 4 / (x_max - x_min)\n",
        "                x0_init = x_mid - np.log((y_max - y_mid) / (y_mid - y_min)) / k_init\n",
        "\n",
        "                popt, _ = curve_fit(logistic_function, valid_elapsed, valid_par_mean, p0=[L_init, k_init, x0_init])\n",
        "                L_opt, k_opt, x0_opt = popt\n",
        "                growth_rate = k_opt\n",
        "                doubling_time = math.log(2) / growth_rate\n",
        "            except:\n",
        "                L_opt, k_opt, x0_opt = np.nan, np.nan, np.nan\n",
        "                growth_rate = np.nan\n",
        "                doubling_time = np.nan\n",
        "        else:\n",
        "            L_opt, k_opt, x0_opt = np.nan, np.nan, np.nan\n",
        "            growth_rate = np.nan\n",
        "            doubling_time = np.nan\n",
        "\n",
        "        results.append({\n",
        "            'Column': column.replace(' Mean', ''),\n",
        "            'Growth Rate (k)': k_opt,\n",
        "            'Doubling Time': doubling_time,\n",
        "            'Max Carrying Capacity (L)': L_opt,\n",
        "            'Midpoint (x0)': x0_opt,\n",
        "            'Time Range': f\"0 to {np.max(valid_elapsed):.2f} hours\" if len(valid_elapsed) > 0 else \"N/A\"\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_excel(output_file, index=False)\n",
        "\n",
        "def plot_smooth_growth_curve(input_file, output_image):\n",
        "    df = pd.read_excel(input_file)\n",
        "    elapsed_time = df['Elapsed']\n",
        "\n",
        "    columns_to_plot = [col for col in df.columns if col.endswith(' Mean')]\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    colors = plt.cm.get_cmap('tab10', len(columns_to_plot))\n",
        "\n",
        "    for i, column in enumerate(columns_to_plot):\n",
        "        mean_data = df[column]\n",
        "        std_column = column.replace(' Mean', ' STD DEV')\n",
        "        std_data = df[std_column]\n",
        "\n",
        "        if not mean_data.isnull().all():\n",
        "            spline_mean = make_interp_spline(elapsed_time, mean_data, k=3)\n",
        "            smooth_time = np.linspace(elapsed_time.min(), elapsed_time.max(), 500)\n",
        "            smooth_mean = spline_mean(smooth_time)\n",
        "\n",
        "            plt.plot(smooth_time, smooth_mean, label=column.replace(' Mean', ''), color=colors(i))\n",
        "            plt.errorbar(elapsed_time, mean_data, yerr=std_data, fmt='o', capsize=2, color=colors(i))\n",
        "\n",
        "    plt.xlabel('Time (hours)')\n",
        "    plt.ylabel('% Confluence')\n",
        "    plt.title('Growth Curve (Outlier)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(np.arange(0, 141, 24))\n",
        "    plt.savefig(output_image, format='png')\n",
        "    plt.close()\n",
        "\n",
        "def process_files(file_list, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for input_file in file_list:\n",
        "        filename = os.path.splitext(os.path.basename(input_file))[0]\n",
        "\n",
        "        mean_std_dev_counts_output = os.path.join(output_dir, f\"{filename}_mean_stdev_counts.xlsx\")\n",
        "        growth_rate_and_doubling_time_output = os.path.join(output_dir, f\"{filename}_GR_DT.xlsx\")\n",
        "        growth_curve_output_image = os.path.join(output_dir, f\"{filename}_growth_curve.png\")\n",
        "\n",
        "        calculate_mean_std_dev_and_counts(input_file, mean_std_dev_counts_output)\n",
        "        calculate_growth_rates_and_doubling_times(mean_std_dev_counts_output, growth_rate_and_doubling_time_output)\n",
        "        plot_smooth_growth_curve(mean_std_dev_counts_output, growth_curve_output_image)\n",
        "\n",
        "def main():\n",
        "    # List of input files\n",
        "    input_files = [\n",
        "        \"\"\n",
        "    ]\n",
        "\n",
        "    output_dir = \"output\"\n",
        "\n",
        "    process_files(input_files, output_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "6xDDcFxWOtdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0Z-9k9zja_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vcFXKzuaja9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ASLk8jrja56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}